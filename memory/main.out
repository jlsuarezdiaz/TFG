\BOOKMARK [-1][-]{part.1}{I Introducci\363n}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introducci\363n}{part.1}% 2
\BOOKMARK [1][-]{section.1.1}{Contextualizaci\363n}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Descripci\363n del problema}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.3}{Estructura del trabajo}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.4}{Bibliograf\355a fundamental}{chapter.1}% 6
\BOOKMARK [1][-]{section.1.5}{Objetivos}{chapter.1}% 7
\BOOKMARK [1][-]{section.1.6}{Materias relacionadas}{chapter.1}% 8
\BOOKMARK [-1][-]{part.2}{II Matem\341ticas}{}% 9
\BOOKMARK [0][-]{chapter.2}{An\341lisis convexo}{part.2}% 10
\BOOKMARK [1][-]{section.2.1}{Conjuntos convexos}{chapter.2}% 11
\BOOKMARK [1][-]{section.2.2}{Funciones convexas}{chapter.2}% 12
\BOOKMARK [1][-]{section.2.3}{Problemas de optimizaci\363n y algoritmos b\341sicos}{chapter.2}% 13
\BOOKMARK [0][-]{chapter.3}{An\341lisis matricial}{part.2}% 14
\BOOKMARK [1][-]{section.3.1}{Preliminares}{chapter.3}% 15
\BOOKMARK [1][-]{section.3.2}{Las matrices como espacio de Hilbert}{chapter.3}% 16
\BOOKMARK [1][-]{section.3.3}{Matrices semidefinidas positivas: teoremas de descomposici\363n y proyecci\363n}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.4}{Cociente de Rayleigh. Optimizaci\363n con vectores propios.}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.5}{\332ltimas consideraciones}{chapter.3}% 19
\BOOKMARK [0][-]{chapter.4}{Teor\355a de la informaci\363n y divergencias}{part.2}% 20
\BOOKMARK [1][-]{section.4.1}{Introducci\363n}{chapter.4}% 21
\BOOKMARK [1][-]{section.4.2}{Las divergencias de Kullback-Leibler y Jeffrey}{chapter.4}% 22
\BOOKMARK [1][-]{section.4.3}{La distribuci\363n normal multivariante y divergencias matriciales.}{chapter.4}% 23
\BOOKMARK [-1][-]{part.3}{III Inform\341tica te\363rica}{}% 24
\BOOKMARK [0][-]{chapter.5}{El aprendizaje autom\341tico}{part.3}% 25
\BOOKMARK [1][-]{section.5.1}{Introducci\363n}{chapter.5}% 26
\BOOKMARK [1][-]{section.5.2}{El aprendizaje supervisado}{chapter.5}% 27
\BOOKMARK [1][-]{section.5.3}{El problema de clasificaci\363n}{chapter.5}% 28
\BOOKMARK [0][-]{chapter.6}{El aprendizaje de m\351tricas de distancia}{part.3}% 29
\BOOKMARK [1][-]{section.6.1}{Distancias. Distancia de Mahalanobis.}{chapter.6}% 30
\BOOKMARK [1][-]{section.6.2}{Descripci\363n del problema}{chapter.6}% 31
\BOOKMARK [1][-]{section.6.3}{Aplicaciones}{chapter.6}% 32
\BOOKMARK [1][-]{section.6.4}{El aprendizaje por semejanza}{chapter.6}% 33
\BOOKMARK [0][-]{chapter.7}{Descripci\363n te\363rica de t\351cnicas de aprendizaje de m\351tricas de distancia}{part.3}% 34
\BOOKMARK [1][-]{section.7.1}{T\351cnicas de reducci\363n de dimensionalidad}{chapter.7}% 35
\BOOKMARK [1][-]{section.7.2}{T\351cnicas orientadas a la mejora del clasificador de vecinos cercanos}{chapter.7}% 36
\BOOKMARK [1][-]{section.7.3}{T\351cnicas orientadas a la mejora del clasificador de centroides cercanos}{chapter.7}% 37
\BOOKMARK [1][-]{section.7.4}{T\351cnicas basadas en teor\355a de la informaci\363n}{chapter.7}% 38
\BOOKMARK [1][-]{section.7.5}{Otras t\351cnicas de aprendizaje de m\351tricas de distancia}{chapter.7}% 39
\BOOKMARK [1][-]{section.7.6}{El kernel trick. Algoritmos de aprendizaje de m\351tricas de distancia basados en kernels}{chapter.7}% 40
\BOOKMARK [-1][-]{part.4}{IV Inform\341tica pr\341ctica}{}% 41
\BOOKMARK [0][-]{chapter.8}{Software desarrollado}{part.4}% 42
\BOOKMARK [1][-]{section.8.1}{Los lenguajes Python y R}{chapter.8}% 43
\BOOKMARK [1][-]{section.8.2}{Descripci\363n del software}{chapter.8}% 44
\BOOKMARK [1][-]{section.8.3}{Uso del software}{chapter.8}% 45
\BOOKMARK [0][-]{chapter.9}{Experimentaci\363n}{part.4}% 46
\BOOKMARK [1][-]{section.9.1}{Descripci\363n de los experimentos}{chapter.9}% 47
\BOOKMARK [1][-]{section.9.2}{Resultados}{chapter.9}% 48
\BOOKMARK [1][-]{section.9.3}{Conclusiones}{chapter.9}% 49
\BOOKMARK [-1][-]{part.5}{V Conclusi\363n}{}% 50
\BOOKMARK [0][-]{chapter.10}{Conclusiones y v\355as futuras}{part.5}% 51
